{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data january of 2023\n",
    "data_jan = pd.read_parquet('./data/homework_1/yellow_tripdata_2023-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 1: What's the standard deviation of the trips duration in January?\n",
    "len(data_jan.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(42.59435124195458)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 2: Now let's compute the duration variable. It should contain the duration of a ride in minutes.\n",
    "# What's the standard deviation of the trips duration in January?\n",
    "\n",
    "# Compute duration in minutes\n",
    "data_jan['duration'] = (data_jan['tpep_dropoff_datetime'] - data_jan['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "\n",
    "# Calculate the standard deviation of the duration\n",
    "std_duration = data_jan['duration'].std()\n",
    "std_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9812202822125979"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 3: Next, we need to check the distribution of the duration variable. \n",
    "# There are some outliers. \n",
    "# Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "# What fraction of the records left after you dropped the outliers?\n",
    "\n",
    "\n",
    "# Filter the data to keep only durations between 1 and 60 minutes (inclusive)\n",
    "filtered_data = data_jan[(data_jan['duration'] >= 1) & (data_jan['duration'] <= 60)]\n",
    "\n",
    "# Calculate the fraction of records left\n",
    "fraction_left = len(filtered_data) / len(data_jan)\n",
    "fraction_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 4: Let's apply one-hot encoding to the pickup and dropoff location IDs. \n",
    "# We'll use only these two features for our model.\n",
    "\n",
    "# - Turn the dataframe into a list of dictionaries (remember to re-cast the ids to strings - otherwise it will label encode them)\n",
    "# - Fit a dictionary vectorizer\n",
    "# - Get a feature matrix from it\n",
    "# What's the dimensionality of this matrix (number of columns)? \n",
    "\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Select only the relevant columns and re-cast the IDs to strings\n",
    "categorical = filtered_data[['PULocationID', 'DOLocationID']].astype(str)\n",
    "\n",
    "# Turn the DataFrame into a list of dictionaries\n",
    "dicts = categorical.to_dict(orient='records')\n",
    "\n",
    "# Fit a dictionary vectorizer\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(dicts)\n",
    "\n",
    "# Get the dimensionality (number of columns)\n",
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(7.649261946248764)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 5: Now let's use the feature matrix from the previous step to train a model.\n",
    "\n",
    "# Train a plain linear regression model with default parameters, where duration is the response variable\n",
    "# Calculate the RMSE of the model on the training data\n",
    "# What's the RMSE on train?\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Prepare the target variable\n",
    "y_train = filtered_data['duration'].values\n",
    "\n",
    "# Train the linear regression model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the training data\n",
    "y_pred = lr.predict(X_train)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(7.811817544074326)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 6: Now let's apply this model to the validation dataset (February 2023).\n",
    "\n",
    "# What's the RMSE on validation?\n",
    "\n",
    "# 1. Read the February data\n",
    "data_feb = pd.read_parquet('./data/homework_1/yellow_tripdata_2023-02.parquet')\n",
    "\n",
    "# 2. Compute the duration in minutes\n",
    "data_feb['duration'] = (data_feb['tpep_dropoff_datetime'] - data_feb['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "\n",
    "# 3. Filter durations between 1 and 60 minutes (inclusive)\n",
    "filtered_feb = data_feb[(data_feb['duration'] >= 1) & (data_feb['duration'] <= 60)]\n",
    "\n",
    "# 4. Prepare the feature matrix using the same DictVectorizer\n",
    "categorical_feb = filtered_feb[['PULocationID', 'DOLocationID']].astype(str)\n",
    "dicts_feb = categorical_feb.to_dict(orient='records')\n",
    "X_val = dv.transform(dicts_feb)  # Use the same dv as before\n",
    "\n",
    "# 5. Prepare the target variable\n",
    "y_val = filtered_feb['duration'].values\n",
    "\n",
    "# 6. Predict and calculate RMSE\n",
    "y_pred_val = lr.predict(X_val)\n",
    "rmse_val = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "rmse_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
